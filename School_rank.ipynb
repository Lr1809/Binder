{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   排名    \t    学校    \t    城市    \t    总分    \n",
      "    1     \t 清华大学 \t    北京    \t   94.6   \n",
      "    2     \t 北京大学 \t    北京    \t   76.5   \n",
      "    3     \t 浙江大学 \t    浙江    \t   72.9   \n",
      "    4     \t上海交通大学\t    上海    \t   72.1   \n",
      "    5     \t 复旦大学 \t    上海    \t   65.6   \n",
      "    6     \t中国科学技术大学\t    安徽    \t   60.9   \n",
      "    7     \t华中科技大学\t    湖北    \t   58.9   \n",
      "    7     \t 南京大学 \t    江苏    \t   58.9   \n",
      "    9     \t 中山大学 \t    广东    \t   58.2   \n",
      "    10    \t哈尔滨工业大学\t   黑龙江    \t   56.7   \n",
      "    11    \t北京航空航天大学\t    北京    \t   56.3   \n",
      "    12    \t 武汉大学 \t    湖北    \t   56.2   \n",
      "    13    \t 同济大学 \t    上海    \t   55.7   \n",
      "    14    \t西安交通大学\t    陕西    \t   55.0   \n",
      "    15    \t 四川大学 \t    四川    \t   54.4   \n",
      "    16    \t北京理工大学\t    北京    \t   54.0   \n",
      "    17    \t 东南大学 \t    江苏    \t   53.6   \n",
      "    18    \t 南开大学 \t    天津    \t   52.8   \n",
      "    19    \t 天津大学 \t    天津    \t   52.3   \n",
      "    20    \t华南理工大学\t    广东    \t   52.0   \n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "import requests\n",
    "import sys\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def getHTML(url):\n",
    "    try:\n",
    "        r = requests.get(url)\n",
    "        r.raise_for_status()\n",
    "        r.encoding = r.apparent_encoding\n",
    "        return r.text\n",
    "    except:\n",
    "        er = sys.exc_info()\n",
    "        #输出错误类型以及错误信息\n",
    "        print(er[0],':',er[1])\n",
    "\n",
    "def Write_in_list(slist,html):\n",
    "    soup = BeautifulSoup(html,\"html.parser\")\n",
    "    for tr in soup.find('tbody').children:  # （1）在soup中找到body!（搜索文档树）\n",
    "        # （2）紧接着遍历body的所有子节点（下行遍历）\n",
    "        # 这句话不好理解可以这样看 在整个soup中找到一个特殊的标签可以这样做\n",
    "        # a = soup.find('tbody') 返回的类型为 <class 'bs4.element.Tag'>\n",
    "        # a.children: 之后再调用children\n",
    "        if isinstance(tr, bs4.element.Tag):  # 过滤tbody子节点中为tr的标签\n",
    "            # print(tr)   #这里看到tr标签中含有很多td标签, 之后提取td标签\n",
    "            tds = tr('td')\n",
    "            #print(tds)  # 这里返回的是每一个大学的信息,不同的大学在不同的列表中\n",
    "            #print(tds[0].string, tds[1].string, tds[2].string, tds[3].string)\n",
    "            #print(type(tds[0]))  # 这里在强调一下 , find_all返回的列表是<class 'bs4.element.Tag'>型列表\n",
    "            # <td><div align=\"left\">上海交通大学</div></td>\n",
    "            # 这里没想明白一个问题 td.string 返回的内容是上海交通大学\n",
    "            # 不应该是 div.string返回的内容才是上海交通大学么？\n",
    "            slist.append([tds[0].string, tds[1].string, tds[2].string, tds[3].string])\n",
    "\n",
    "    return slist\n",
    "\n",
    "def display_list(slist,num):\n",
    "    print(\"{:^9}\\t{:^10}\\t{:^10}\\t{:^10}\".format(\"排名\",\"学校\",\"城市\",\"总分\"))\n",
    "    for i in range(num):\n",
    "        u = slist[i]\n",
    "        print(\"{:^10}\\t{:^6}\\t{:^10}\\t{:^10}\".format(u[0],u[1],u[2],u[3]))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    num = 20\n",
    "    url = \"http://www.zuihaodaxue.cn/zuihaodaxuepaiming2019.html\"\n",
    "    sc_list = []\n",
    "    html = getHTML(url)\n",
    "    sc_list = Write_in_list(sc_list,html)\n",
    "    display_list(sc_list, num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://www.cnblogs.com/caesura-k/p/9655765.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
